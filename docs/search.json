{
  "articles": [
    {
      "path": "abstracts.html",
      "title": "Abstracts",
      "description": "Below are the abstracts for the talks, in the order of the presentation. ",
      "author": [],
      "contents": "\n\n\nOral Presentations\nBlock 1: Theoretical Statistics\nIchiro Hashimoto\nUniversality of Benign Overfitting in Binary Linear Classification\nThe practical success of deep learning has led to the discovery of several surprising phenomena. One of these phenomena, that has spurred intense theoretical research, is ``benign overfitting’’: deep neural networks seem to generalize well in the over-parametrized regime even though the networks show a perfect fit to noisy training data. It is now known that benign overfitting also occurs in various classical statistical models. For linear maximum margin classifiers, benign overfitting has been established theoretically in a class of mixture models with very strong assumptions on the covariate distribution. However, even in this simple setting, many questions remain open. For instance, most of the existing literature focuses on the noiseless case where all true class labels are observed without errors, whereas the more interesting noisy case remains poorly understood. We provide a comprehensive study of benign overfitting for linear maximum margin classifiers. We discover a phase transition in test error bounds for the noisy model which was previously unknown and provide some geometric intuition behind it. We further considerably relax the required covariate assumptions in both, the noisy and noiseless case. Our results demonstrate that benign overfitting of maximum margin classifiers holds in a much wider range of scenarios than was previously known and provide new insights into the underlying mechanisms.\nBingqing Li\nRegression based EM Algorithm\nHigh-dimensional clustering is a crucial yet challenging problem in statistics and machine learning. We propose a novel method that addresses these challenges by capturing the low-rank structure of the data. Our approach employs a Gaussian mixture model on the low-rank signal, enabling efficient and effective multiclass clustering. The method is computationally fast, leveraging Principal Component Analysis (PCA) as an initial transformation to project the data into a lower-dimensional space.This is followed by iterative updates of the projection matrix for clustering in the reduced subspace.Through comprehensive simulations across diverse scenarios, our method consistently outperforms existing techniques on high-dimensional datasets, providing a robust framework for high-dimensional clustering with enhanced efficiency. Inspired by Fisher Discriminant Analysis, we also propose a novel 2D visualization technique. This method projects high-dimensional data into a 2D space using information from the estimated labels, offering a distinctive visualization approach in unsupervised learning scenarios.\nBlock 2: Applied Statistics\nMandy Yao\nQuantifying Uncertainty in Air Pollution Machine Learning Models\nGiven the ongoing climate crisis and increase in extreme weather events, it is now more important than ever to study the role of the environment on human health. Given the abundance and complexity of environmental data from multiple sources, machine learning (ML) methods have risen in popularity over more traditional statistical methods to explore, understand, and capture spatial and temporal trends. Yet, many ML methods have limited or no ability to quantify uncertainty, which is often needed to make insightful interpretations about predictions. We examine a popular ML method, Extreme Gradient Boosting (XGBoost), and show how a modified quantile regression can be incorporated to construct point-wise prediction intervals of specific quantiles, while allowing XGBoost to perform well by finding solutions rapidly using optimal gradient descent rates. We then compare our method to another modified quantile regression method (which uses an arctan pinball loss function), and to the implementation of quantile regression for XGBoost in the xgboost python package, by predicting particulate matter air quality exposures in California that capture wildfire events.\nLin Yu\nCausal Variance Decompositions for Measuring Health Inequalities\nRacial disparities in healthcare are well-documented, but what drives them? Is it differences in hospital quality, unequal access, or hospitals treating patients differently based on race? To answer these questions, we propose a new causal decomposition method that partitions the observed variation in care received (e.g., assignment of a treatment) into five components: 1) variation due to race, 2) variation in hospital quality, 3) effect modification (differential treatment within hospitals), 4) differential access to hospitals, and 5) residual. Our method overcomes the limitations of traditional effect modification approaches by enabling overall evaluation of variation of multi-categorical variables, rather than relying on pairwise comparisons, thus allowing for assessment of the validity of the quality indicator for hospital performance comparison. Additionally, our method enhances existing variance decomposition methods by introducing two new causal estimands that interpret variance from effect modification and differential access. We propose both parametric (generalized linear models, generalized linear mixed-effect models) and nonparametric (Random Forest and XGboost) estimators for the causal components. Although initially conceptualized to address racial disparities, our method is generalizable and can be applied to study other disparities in healthcare and other domains. Simulation results show the proposed estimators capture the true causal estimands well except for small sample bias.\nTianyi Pan\nEstimating Associations Between Cumulative Exposure and Health via Generalized Distributed Lag Non-Linear Models using Penalized Splines\nQuantifying associations between short-term exposure to ambient air pollution and health outcomes is an important public health priority. Historically, studies have restricted attention to single-day exposures or (equally weighted) average exposure over several days. Adaptive cumulative exposure distributed lag non-linear models (ACE-DLNMs), in contrast, quantify associations between health outcomes and cumulative exposure that is specified in a data-adaptive way. While the ACE-DLNM framework is highly interpretable, it is limited to continuous outcomes and does not scale well to large datasets. Motivated by a large analysis of daily pollution and circulatory and respiratory hospitalizations in Canada between 2001 and 2018, we propose a generalized ACE-DLNM incorporating penalized splines, and we propose an efficient estimation strategy based on profile likelihood and Laplace approximate marginal likelihood with Newton-type methods. Our proposed method improves upon existing approaches in three ways: (1) it applies to general response types, including over-dispersed counts; (2) estimation is computationally efficient and readily applies to large datasets; and (3) it treats the exposure process continuously with respect to time. In application to the motivating analysis, the proposed method respects the discrete responses and reduces uncertainty in estimated associations compared to generalized additive models with fixed exposures.\nBlock 3: Mathematical Finance and Actuarial Science\nHassan Abdelrahman\nSimplifying Complexities in IBNR Claims Count Estimation With A Bayesian GLM Approach\nEstimating the count of incurred but not reported (IBNR) claims is a fundamental challenge in loss reserving. The Chain Ladder method, a widely used macro-level approach, relies on aggregated claims data and provides a simple framework for reserve estimation. However, it can be inaccurate in many cases as it does not leverage detailed claims information and may introduce biases under certain conditions. To address these limitations, micro-level models have been developed to incorporate individual claim data, capturing claim occurrence and reporting dynamics more effectively. Recent literature has shown that these models outperform the Chain Ladder method in predictive accuracy.\nDespite their better performance, micro-level models remain largely unused in practice due to their computational complexity and various modeling challenges. In this paper, we propose a Bayesian framework that builds on the Chain Ladder method while incorporating key micro-level elements, bridging the gap between these two approaches. Through case studies, we demonstrate that our framework not only outperforms the classical Chain Ladder method but also surpasses micro-level models adopted in recent literature, offering a practical and scalable alternative for IBNR claim count estimation.\nBrandon Tam\nDimension Reduction of Distributionally Robust Optimization Problems\nWe study distributionally robust optimization (DRO) problems with uncertainty sets consisting of high dimensional random vectors that are close in the multivariate Wasserstein distance to a reference random vector. We give conditions under which the images of these sets under scalar-valued aggregation functions are equal to or contained in uncertainty sets of univariate random variables defined via a univariate Wasserstein distance. This allows to rewrite or bound high-dimensional DRO problems with simpler DRO problems over the space of univariate random variables. We generalize the results to uncertainty sets defined via the Bregman-Wasserstein divergence and the max-sliced Wasserstein and Bregman-Wasserstein divergence. The max-sliced divergences allow us to jointly model distributional uncertainty around the reference random vector and uncertainty in the aggregation function. Finally, we derive explicit bounds for worst-case risk measures that belong to the class of signed Choquet integrals.\nBlock 4: Graphical Models\nPhilip Choi\nInference for graphical models for extremes\nExtreme value theory is the study of the tail region of a distribution, where empirical estimation is often impossible due to the lack of extreme data. In real-life situations, such as quantifying the risks of floods or financial crises, we are sometimes interested in the dependence of extremes. For example, how does a high water level at one measuring site relate to water levels at other measuring sites? In high-dimensional settings, tail dependence can become arbitrarily complex. Hence, sparsity is required to obtain interpretable models. The classical notion of graphical models fails for extremes, but an appropriate notion of conditional independence for extremes was proposed in 2020 by Engelke and Hitz. Since then, several data-driven estimators for graphical models for extremes have been developed. In this talk, I will discuss my current progress in building a framework for inference for these estimators. In particular, I will focus on Hüsler–Reiss graphical models for extremes, which can be thought of as analogous to Gaussian graphical models.\nMorris Greenberg\nRestricted Search Space Graph MCMC via Birth-Death Processes\nInferring a directed acyclic graph (DAG) given data is computationally challenging due to graphs existing in a discrete search space that grows super-exponentially with the number of nodes. A promising class of MCMC methods for graph inference addresses scalability by first restricting the search space to a subset of edges (where partial scores can be calculated in advance), and thereafter incrementally expanding the space until a stopping criterion is met.\nIn this work, we estimate lower and upper bounds on the error introduced from current methods that operate on restricted spaces instead of the full space. Building on this, we propose a novel restricted-search MCMC method that reduces these errors. Our method is an adaptive algorithm which allows for either expansion or contraction of the search space throughout the chain. This is determined by a birth-death process, which we derive by choosing birth and death rates which are informed by our error bounds. Additionally, we improve upon the computational costs of previous restricted-search methods by including block-matrix operations in expansion steps and memoization in contraction steps.\nWe present extensive simulations that characterize the performance and computational efficiency of our algorithm, contrast this with existing methods, and consider applications in the field of imaging proteomics.\n\n\n\n",
      "last_modified": "2025-04-21T22:09:44-04:00"
    },
    {
      "path": "index.html",
      "title": "University of Toronto Statistics Graduate Student Research Day 2025",
      "author": [],
      "contents": "\nAbout\nStatistics Graduate Student Research Day is an annual conference organized by graduate students in the Department of Statistical Sciences at the University of Toronto. The event celebrates and showcases the exciting work of graduate students in the areas of statistics, mathematical sciences, and actuarial science. This conference also serves as a valuable networking opportunity, bringing together students from across disciplines to connect with the broader statistical sciences community.\nThis year’s event will take place in person at the Department of Statistical Sciences, located on the 9th floor of the Ontario Power Building, 700 University Avenue, Toronto, ON, M5G 1Z5. The talks and poster session will be held in the Maple and Cherry Rooms (9014 and 9016). A small breakfast (pastries and coffee) will be provided at 9:30 a.m. Opening remarks will begin at 9:45 a.m., followed by the first round of talks at 10:00 a.m. Lunch will be provided at 12:45 p.m. The poster session will be held at 2:30 p.m. The conference will conclude at approximately 5:00 p.m., after the closing remarks.\nThe schedule can be found here. The event has four thematic blocks, corresponding to the main research areas in our department: Theoretical Statistics, Applied Statistics, Mathematical Finance and Actuarial Science, and Graphical Models. The abstracts can be found here. If you have any questions, please do not hesitate to reach out to a member of the organizing committee.\nEvent organizing committee\n\n\nNnenna Asidianya\n\n\nElijah French\n\n\nBushra Haque\n\n\nRuyi Pan\n\n\nYaqi Shi\n\n\nFred Song\n\n\nKC Tsiolis\n\n\nMandy Yao\n\n\nJingxin (Owen) Wang\n\n\nAcknowledgments\nThe organizing committee extends sincere thanks to faculty advisors Dr. Sebastian Jaimungal, Dr. Stanislav Volgushev, and Dr. Piotr Zwiernik, as well as staff members Angela Fleury, Karla Barrera, and Kachely Peters for their guidance and support in planning this event.\nWe are also grateful to the Department of Statistical Sciences at the University of Toronto for their generous funding and logistical support.\nLand Acknowledgment\nWe respectfully acknowledge the land on which the University of Toronto operates. For thousands of years, it has been the traditional territory of the Huron-Wendat, the Seneca, and the Mississaugas of the Credit. Today, this meeting place remains home to many Indigenous peoples from across Turtle Island, and we are grateful for the opportunity to work and learn on this land.\n\n\n\n\n\n\n\n",
      "last_modified": "2025-04-21T22:10:29-04:00"
    },
    {
      "path": "schedule.html",
      "title": "Schedule",
      "description": "Below is the official schedule for the event. All times are in EDT.",
      "author": [],
      "contents": "\nOpening Remarks\nTime: 9:45-10:00\nSpeaker: KC Tsiolis (DoSS)\nBlock 1: Theoretical Statistics\nChair: KC Tsiolis (DoSS)\nTime\nTitle\nSpeaker\n10:00–10:30\nUniversality of Benign Overfitting in Binary Linear Classification (abstract)\nIchiro Hashimoto (DoSS)\n10:30–11:00\nRegression based EM Algorithm (abstract)\nBingqing Li (DoSS)\nBlock 2: Applied Statistics\nChair: Yaqi Shi (DoSS)\nTime\nTitle\nSpeaker\n11:15–11:45\nQuantifying Uncertainty in Air Pollution Machine Learning Models (abstract)\nMandy Yao (DoSS)\n11:45–12:15\nCausal Variance Decompositions for Measuring Health Inequalities (abstract)\nLin Yu (Public Health)\n12:15–12:45\nEstimating Associations Between Cumulative Exposure and Health via Generalized Distributed Lag Non-Linear Models using Penalized Splines (abstract)\nTianyi Pan (Waterloo Stats & ActSci)\nLunch\nTime: 12:45–13:30\nBlock 3: Mathematical Finance and Actuarial Science\nChair: Elijah French (DoSS)\nTime\nTitle\nSpeaker\n13:30–14:00\nSimplifying Complexities in IBNR Claims Count Estimation With A Bayesian GLM Approach (abstract)\nHassan Abdelrahman (DoSS)\n14:00–14:30\nDimension Reduction of Distributionally Robust Optimization Problems (abstract)\nBrandon Tam (DoSS)\nPoster Session\nTime: 14:30–15:45\nBlock 4: Graphical Models\nChair: Ruyi Pan (DoSS)\nTime\nTitle\nSpeaker\n15:45–16:15\nInference for Graphical Models for Extremes (abstract)\nPhilip Choi (DoSS)\n16:15–16:45\nRestricted Search Space Graph MCMC via Birth-Death Processes (abstract)\nMorris Greenberg (DoSS)\n\n\n\n",
      "last_modified": "2025-04-21T22:09:45-04:00"
    }
  ],
  "collections": []
}
